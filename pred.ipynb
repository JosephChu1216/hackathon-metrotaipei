{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "MODEL_PATH = \"models/violenceModel_baseOn_inceptionV3.h5\"\n",
    "LABEL_BIN = \"models/lb.pickle\"\n",
    "\n",
    "args = {\n",
    "    \"input\": \"dataset/real life violence situations/Real Life Violence Dataset/Violence/V_1.mp4\",\n",
    "    \"output\": \"output/streetfight_64avg.avi\",\n",
    "    \"size\": 64  \n",
    "}\n",
    "\n",
    "def violence_inference(args):\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "\n",
    "    # load the trained model and label binarizer from disk\n",
    "    print(\"[INFO] loading model and label binarizer...\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "    lb = pickle.loads(open(LABEL_BIN, \"rb\").read())\n",
    "\n",
    "    # initialize the image mean for mean subtraction along with the\n",
    "    # predictions queue\n",
    "    mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
    "    Q = deque(maxlen=args[\"size\"])\n",
    "\n",
    "    # initialize the video stream, pointer to output video file, and\n",
    "    # frame dimensions\n",
    "    vpath = args[\"input\"]\n",
    "    if args[\"input\"] == 'camera':\n",
    "        vpath = 0\n",
    "    vs = cv2.VideoCapture(vpath)\n",
    "    writer = None\n",
    "    (W, H) = (None, None)\n",
    "\n",
    "    # loop over frames from the video file stream\n",
    "\n",
    "    pred_prob_max = 0\n",
    "    pred_prob_max_frame = 0\n",
    "    while True:\n",
    "        # read the next frame from the file\n",
    "        (grabbed, frame) = vs.read()\n",
    "\n",
    "        # if the frame was not grabbed, then we have reached the end\n",
    "        # of the stream\n",
    "        if not grabbed:\n",
    "            break\n",
    "\n",
    "        # if the frame dimensions are empty, grab them\n",
    "        if W is None or H is None:\n",
    "            (H, W) = frame.shape[:2]\n",
    "\n",
    "        # clone the output frame, then convert it from BGR to RGB\n",
    "        # ordering, resize the frame to a fixed 224x224, and then\n",
    "        # perform mean subtraction\n",
    "        output = frame.copy()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
    "        frame -= mean\n",
    "\n",
    "        # make predictions on the frame and then update the predictions\n",
    "        # queue\n",
    "        preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "        Q.append(preds)\n",
    "        results = np.array(Q)[-1]\n",
    "        i=1\n",
    "        label = lb.classes_[i]\n",
    "\n",
    "\n",
    "        # draw the activity on the output frame\n",
    "        # prob = model.predict_proba(np.expand_dims(frame, axis=0))[0] # to show probability of frame\n",
    "        prob = results[i]*100\n",
    "\n",
    "        text_color = (0, 255, 0) # default : green\n",
    "\n",
    "        if prob > 40 : # Violence prob\n",
    "            text_color = (0, 0, 255) # red\n",
    "\n",
    "        else:\n",
    "            label = 'Normal'\n",
    "\n",
    "        text = \"State : {:8} ({:3.2f}%)\".format(label,prob)\n",
    "        FONT = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "        cv2.putText(output, text, (35, 50), FONT,1.25, text_color, 3) \n",
    "\n",
    "        # plot graph over background image\n",
    "        output = cv2.rectangle(output, (35, 80), (35+int(prob)*5,80+20), text_color,-1)\n",
    "        # check if the video writer is None\n",
    "        if writer is None:\n",
    "            # initialize our video writer\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "            writer = cv2.VideoWriter(args[\"output\"], fourcc, 30,(W, H), True)\n",
    "\n",
    "        # write the output frame to disk\n",
    "        pred_prob_max,pred_prob_max_frame = (preds[1],output) if preds[1]>pred_prob_max else (pred_prob_max,pred_prob_max_frame)\n",
    "        writer.write(output)\n",
    "        cv2.imwrite(\"./output/pred_prob_max_frame.jpg\",pred_prob_max_frame)\n",
    "\n",
    "    # release the file pointersq\n",
    "    print(\"[INFO] cleaning up...\")\n",
    "    writer.release()\n",
    "    vs.release()\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4548b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cb0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49fe5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbbde0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
